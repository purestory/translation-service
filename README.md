# ë²ˆì—­ ì„œë¹„ìŠ¤ (Translation Service)

AI ê¸°ë°˜ ë‹¤ì¤‘ ì—”ì§„ ë²ˆì—­ ì›¹ ì„œë¹„ìŠ¤ - GPU ê°€ì† ë¡œì»¬ AI ëª¨ë¸ íŠ¹í™”

## ğŸŒ ì„œë¹„ìŠ¤ ì ‘ì†

- **ì›¹ ì‚¬ì´íŠ¸**: http://itsmyzone.iptime.org/translation/
- **API**: http://itsmyzone.iptime.org/translation-api/

## ğŸ—ï¸ ì„œë¹„ìŠ¤ êµ¬ì¡°

```
ë²ˆì—­ ì„œë¹„ìŠ¤
â”œâ”€â”€ í”„ë¡ íŠ¸ì—”ë“œ: React + Vite â†’ nginx (í¬íŠ¸ 80/443)
â”œâ”€â”€ ë°±ì—”ë“œ: Node.js Express â†’ systemd (í¬íŠ¸ 3501)
â””â”€â”€ AI ëª¨ë¸: Ollama Docker Container â†’ GPU ê°€ì† (í¬íŠ¸ 11434)
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ì €ì¥ì†Œ í´ë¡ 
```bash
git clone https://github.com/purestory/translation-service.git
cd translation-service
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
# backend/.env íŒŒì¼ ìƒì„±
cp backend/.env.example backend/.env

# í•„ìš”í•œ API í‚¤ ì„¤ì • (ì„ íƒì‚¬í•­)
DEEPL_API_KEY=your_deepl_key
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key
GEMINI_API_KEY=your_gemini_key
GROQ_API_KEY=your_groq_key
OLLAMA_URL=http://localhost:11434
```

### 3. ì˜ì¡´ì„± ì„¤ì¹˜
```bash
# ë°±ì—”ë“œ ì˜ì¡´ì„± ì„¤ì¹˜
cd backend
npm install

# í”„ë¡ íŠ¸ì—”ë“œ ì˜ì¡´ì„± ì„¤ì¹˜
cd ../vite-frontend
npm install
```

### 4. Ollama ì„¤ì¹˜ ë° ì‹¤í–‰
```bash
# Dockerë¡œ Ollama ì‹¤í–‰
sudo docker run -d --name ollama \
  -p 11434:11434 \
  --gpus all \
  -v ollama_data:/root/.ollama \
  ollama/ollama

# í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
sudo docker exec ollama ollama pull gemma2:9b
```

### 5. ì„œë¹„ìŠ¤ ì‹¤í–‰
```bash
# ë°±ì—”ë“œ ì‹¤í–‰
cd backend
npm start

# í”„ë¡ íŠ¸ì—”ë“œ ë¹Œë“œ ë° ì‹¤í–‰ (ê°œë°œì‹œ)
cd ../vite-frontend
npm run dev
```

## ğŸ¤– ì§€ì› ë²ˆì—­ ì—”ì§„

### GPU ê°€ì† Ollama ëª¨ë¸ (ìš°ì„ ìˆœìœ„)
1. **ollama-gemma2-sapie** (ê¸°ë³¸ê°’) - í•œêµ­ì–´ íŠ¹í™” Sapie ëª¨ë¸
2. **ollama-kanana-1.5** - Kakao Corp. Kanana 1.5-8B (BF16+Q8_0, 9.5GB)
3. **ollama-exaone3.5** - LG AI Research Exaone 3.5 (í•œêµ­ì–´ íŠ¹í™”)
4. **ollama-gemma2** - Google Gemma2 9B
5. **ollama-hyperclovax** - Naver HyperCLOVAX 3B (í•œêµ­ì–´ íŠ¹í™”)
6. **ollama-hyperclovax-1.5b** - Naver HyperCLOVAX 1.5B (ê²½ëŸ‰í™”)

### í´ë¼ìš°ë“œ API ëª¨ë¸ (ëŒ€ì²´ ì—”ì§„)
- **Google Gemini** - ê³ í’ˆì§ˆ ë‹¤êµ­ì–´ ë²ˆì—­
- **Groq Llama** - ê³ ì† ì¶”ë¡ 
- **OpenAI GPT** - ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­
- **Anthropic Claude** - ë¬¸ë§¥ ì´í•´ ìš°ìˆ˜
- **DeepL** - ì „ë¬¸ ë²ˆì—­ ì„œë¹„ìŠ¤

## ğŸ”§ í•˜ë“œì›¨ì–´ ì‚¬ì–‘

### GPU ì •ë³´
- **ëª¨ë¸**: NVIDIA RTX 3090
- **VRAM**: 24GB
- **CUDA**: 12.8
- **ì»´í“¨íŠ¸ ëŠ¥ë ¥**: 8.6 (BF16 ì§€ì›)

### AI ëª¨ë¸ í˜„í™©
```bash
# ì„¤ì¹˜ëœ ëª¨ë¸ í™•ì¸
curl -s http://localhost:11434/api/tags | jq '.models[].name'

# GPU ì‚¬ìš©ëŸ‰ í™•ì¸
nvidia-smi
```

## ğŸ”§ ì„œë¹„ìŠ¤ ê´€ë¦¬

### ìƒíƒœ í™•ì¸
```bash
# ë²ˆì—­ ì„œë¹„ìŠ¤ ìƒíƒœ
sudo systemctl status translation-service

# Ollama ì»¨í…Œì´ë„ˆ ìƒíƒœ
sudo docker ps | grep ollama

# GPU ì‚¬ìš©ëŸ‰
nvidia-smi

# ì„œë¹„ìŠ¤ ë¡œê·¸
sudo journalctl -u translation-service -f --no-pager
```

### ì„œë¹„ìŠ¤ ì œì–´
```bash
# ë²ˆì—­ ì„œë¹„ìŠ¤ ì¬ì‹œì‘
sudo systemctl restart translation-service

# Ollama ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
sudo docker restart ollama

# ì „ì²´ ì‹œìŠ¤í…œ ì¬ì‹œì‘
sudo systemctl restart translation-service
sudo docker restart ollama
sudo nginx -s reload
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
translation-service/
â”œâ”€â”€ README.md              # í”„ë¡œì íŠ¸ ë¬¸ì„œ
â”œâ”€â”€ package.json           # ë£¨íŠ¸ íŒ¨í‚¤ì§€ ì„¤ì •
â”œâ”€â”€ .gitignore            # Git ë¬´ì‹œ íŒŒì¼
â”œâ”€â”€ backend/              # Node.js ë°±ì—”ë“œ
â”‚   â”œâ”€â”€ server.js         # ë©”ì¸ ì„œë²„
â”‚   â”œâ”€â”€ package.json      # ë°±ì—”ë“œ ì˜ì¡´ì„±
â”‚   â”œâ”€â”€ .env.example      # í™˜ê²½ë³€ìˆ˜ ì˜ˆì œ
â”‚   â”œâ”€â”€ routes/           # API ë¼ìš°íŠ¸
â”‚   â”‚   â””â”€â”€ translation.js # ë²ˆì—­ API ì—”ë“œí¬ì¸íŠ¸
â”‚   â”œâ”€â”€ services/         # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â”‚   â””â”€â”€ translationService.js # ë©”ì¸ ë²ˆì—­ ì„œë¹„ìŠ¤
â”‚   â”œâ”€â”€ utils/            # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”‚   â”œâ”€â”€ uploads/          # ì—…ë¡œë“œ íŒŒì¼ ì„ì‹œ ì €ì¥
â”‚   â””â”€â”€ debug.log         # ì„œë²„ ë¡œê·¸
â”œâ”€â”€ vite-frontend/        # React í”„ë¡ íŠ¸ì—”ë“œ
â”‚   â”œâ”€â”€ src/              # ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”‚   â”œâ”€â”€ App.tsx       # ë©”ì¸ React ì»´í¬ë„ŒíŠ¸
â”‚   â”‚   â”œâ”€â”€ components/   # React ì»´í¬ë„ŒíŠ¸ë“¤
â”‚   â”‚   â””â”€â”€ types/        # TypeScript íƒ€ì… ì •ì˜
â”‚   â”œâ”€â”€ public/           # ì •ì  íŒŒì¼
â”‚   â”œâ”€â”€ dist/             # ë¹Œë“œ ê²°ê³¼ (nginx ì„œë¹™)
â”‚   â”œâ”€â”€ package.json      # í”„ë¡ íŠ¸ì—”ë“œ ì˜ì¡´ì„±
â”‚   â””â”€â”€ vite.config.ts    # Vite ì„¤ì •
â””â”€â”€ tmp/                  # ì„ì‹œ íŒŒì¼ (nginx ì„¤ì • ë“±)
```

## ğŸ› ï¸ ê°œë°œ ë° ë°°í¬

### 1. í”„ë¡ íŠ¸ì—”ë“œ ìˆ˜ì •ì‹œ
```bash
cd vite-frontend
# ì½”ë“œ ìˆ˜ì • í›„
npm run build
# ë°°í¬ ì„œë²„ì—ì„œëŠ” nginx ì¬ë¡œë“œ
sudo nginx -s reload
```

### 2. ë°±ì—”ë“œ ìˆ˜ì •ì‹œ
```bash
cd backend
# ì½”ë“œ ìˆ˜ì • í›„
npm start  # ê°œë°œì‹œ
# ë˜ëŠ”
sudo systemctl restart translation-service  # ìš´ì˜ì‹œ
```

### 3. AI ëª¨ë¸ ì¶”ê°€ì‹œ
```bash
# ìƒˆ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
sudo docker exec ollama ollama pull <model_name>

# ì»¤ìŠ¤í…€ ëª¨ë¸ ë“±ë¡
sudo docker exec ollama ollama create <custom_name> -f /path/to/Modelfile

# ë°±ì—”ë“œì—ì„œ ì—”ì§„ ì¶”ê°€ í›„ ì¬ì‹œì‘ í•„ìš”
```

## ğŸ“Š API ë¬¸ì„œ

### ì£¼ìš” ì—”ë“œí¬ì¸íŠ¸

#### í…ìŠ¤íŠ¸ ë²ˆì—­
```bash
POST /translation-api/translation/text
Content-Type: application/json

{
  "text": "ë²ˆì—­í•  í…ìŠ¤íŠ¸",
  "targetLang": "ko",
  "sourceLang": "en",  // ì„ íƒì‚¬í•­ (auto ê°ì§€)
  "engine": "ollama-gemma2-sapie"  // ì„ íƒì‚¬í•­
}
```

#### íŒŒì¼ ë²ˆì—­ (ìë§‰)
```bash
POST /translation-api/subtitle/translate
Content-Type: multipart/form-data

- file: SRT/VTT íŒŒì¼
- targetLang: ko
- engine: ollama-gemma2-sapie
- chunkSize: 10
```

#### ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ì§„ ëª©ë¡
```bash
GET /translation-api/translation/engines
```

#### ì§€ì› ì–¸ì–´ ëª©ë¡
```bash
GET /translation-api/translation/languages
```

## ğŸš¨ ë¬¸ì œ í•´ê²°

### ë²ˆì—­ì´ ì•ˆë  ë•Œ
1. ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸: `sudo systemctl status translation-service`
2. Ollama ìƒíƒœ í™•ì¸: `sudo docker ps | grep ollama`
3. GPU ë©”ëª¨ë¦¬ í™•ì¸: `nvidia-smi`
4. ë¡œê·¸ í™•ì¸: `sudo journalctl -u translation-service -n 20`
5. ì„œë¹„ìŠ¤ ì¬ì‹œì‘: `sudo systemctl restart translation-service`

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

#### Ollama ì»¨í…Œì´ë„ˆê°€ ì •ì§€ë¨
```bash
# ì›ì¸: GPU ë©”ëª¨ë¦¬ ë¶€ì¡±, CUDA ì˜¤ë¥˜ ë“±
# í•´ê²°: ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
sudo docker start ollama

# ë¡œê·¸ í™•ì¸
sudo docker logs ollama --tail 50
```

#### 500 Internal Server Error
```bash
# ì›ì¸: ë°±ì—”ë“œ ì˜¤ë¥˜, Ollama ì—°ê²° ì‹¤íŒ¨
# í•´ê²°: ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ í›„ ì¬ì‹œì‘
sudo systemctl status translation-service
sudo docker ps | grep ollama
```

#### GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ
```bash
# GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
nvidia-smi

# Ollama ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘ (ëª¨ë¸ ì–¸ë¡œë“œ)
sudo docker restart ollama

# ë¬´ê±°ìš´ ëª¨ë¸ ì œê±°
sudo docker exec ollama ollama rm <heavy_model>
```

### ì›¹ì‚¬ì´íŠ¸ê°€ ì•ˆ ì—´ë¦´ ë•Œ
1. nginx ìƒíƒœ í™•ì¸: `sudo systemctl status nginx`
2. ë¹Œë“œ íŒŒì¼ í™•ì¸: `ls -la vite-frontend/dist/`
3. í¬íŠ¸ í™•ì¸: `lsof -i :80,443,3501`
4. nginx ì¬ë¡œë“œ: `sudo nginx -s reload`

## ğŸ“Š í˜„ì¬ ìš´ì˜ ìƒí™©

### ğŸ¯ í™œì„± ì„¤ì •
- **ê¸°ë³¸ ì—”ì§„**: `ollama-gemma2-sapie` (í•œêµ­ì–´ íŠ¹í™”)
- **ê¸°ë³¸ ì²­í¬ í¬ê¸°**: 10
- **ê¸°ë³¸ ë²ˆì—­ ëª¨ë“œ**: srt_direct
- **ìµœëŒ€ íŒŒì¼ í¬ê¸°**: 10MB
- **ëŒ€ì²´ ì—”ì§„**: í™œì„±í™” (ìë™ í´ë°±)

### ğŸš€ ì„±ëŠ¥ ìµœì í™”
- **GPU ê°€ì†**: RTX 3090 (24GB VRAM)
- **BF16 ì •ë°€ë„**: ì§€ì›ë¨
- **ë™ì‹œ ë²ˆì—­**: ì²­í¬ ë‹¨ìœ„ ë³‘ë ¬ ì²˜ë¦¬
- **ì‹¤ì‹œê°„ ì§„í–‰ë¥ **: WebSocket ìŠ¤íƒ€ì¼ í´ë§

### ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„ (í•œêµ­ì–´)
1. **Kanana 1.5** - Kakao (ì½”ë”©/ìˆ˜í•™/í•¨ìˆ˜í˜¸ì¶œ íŠ¹í™”)
2. **Sapie** - í•œêµ­ì–´ íŠ¹í™” Gemma2 íŠœë‹
3. **Exaone 3.5** - LG AI Research (í•œêµ­ì–´)
4. **HyperCLOVAX** - Naver (í•œêµ­ì–´)

## ğŸ”‘ ì§€ì› ê¸°ëŠ¥

### ë²ˆì—­ ê¸°ëŠ¥
- **ë‹¤ì¤‘ ì—”ì§„**: 6ê°œ ë¡œì»¬ AI + 5ê°œ í´ë¼ìš°ë“œ API
- **ìë™ ëŒ€ì²´**: ì—”ì§„ ì‹¤íŒ¨ì‹œ ìë™ í´ë°±
- **ì‹¤ì‹œê°„ ì§„í–‰ë¥ **: ì²­í¬ë³„ ì§„í–‰ìƒí™© í‘œì‹œ
- **ë°°ì¹˜ ë²ˆì—­**: ëŒ€ìš©ëŸ‰ íŒŒì¼ ì•ˆì • ì²˜ë¦¬

### ìë§‰ ì§€ì›
- **íŒŒì¼ í˜•ì‹**: SRT, VTT, ASS
- **ë²ˆì—­ ëª¨ë“œ**: ìë™, SRT ì§ì ‘, êµ¬ë¶„ì
- **íƒ€ì„ìŠ¤íƒ¬í”„**: ì›ë³¸ ìœ ì§€
- **ì¸ì½”ë”©**: UTF-8 ìë™ ë³€í™˜

### API ê¸°ëŠ¥
- **RESTful API**: í‘œì¤€ HTTP API
- **ì‹¤ì‹œê°„ ì§„í–‰ë¥ **: ê¸´ ë²ˆì—­ ì‘ì—… ëª¨ë‹ˆí„°ë§
- **ì˜¤ë¥˜ ì²˜ë¦¬**: ìƒì„¸í•œ ì˜¤ë¥˜ ë©”ì‹œì§€
- **CORS ì§€ì›**: í¬ë¡œìŠ¤ ë„ë©”ì¸ ìš”ì²­

## âš ï¸ ì¤‘ìš” ìš´ì˜ ê·œì¹™

### âœ… í•´ì•¼ í•  ê²ƒ
- ì½”ë“œ ìˆ˜ì • í›„ ë°˜ë“œì‹œ í…ŒìŠ¤íŠ¸
- ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš© (`/home/purestory/...`)
- systemdë¡œ ì„œë¹„ìŠ¤ ê´€ë¦¬
- Dockerë¡œ Ollama ê´€ë¦¬
- GPU ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§

### âŒ í•˜ì§€ ë§ ê²ƒ
- `~` ê²½ë¡œ ì‚¬ìš© (ì˜ë„ì¹˜ ì•Šì€ í´ë” ìƒì„±)
- pm2 ì‚¬ìš© (systemd ì‚¬ìš© ì¤‘)
- í¬íŠ¸ ë²ˆí˜¸ ì„ì˜ ë³€ê²½
- Ollama ëª¨ë¸ì„ ì§ì ‘ ì‚­ì œ
- GPU ì˜¤ë²„í´ëŸ­ (ì•ˆì •ì„± ìš°ì„ )

## ğŸ”„ ì—…ë°ì´íŠ¸ íˆìŠ¤í† ë¦¬

### 2025-06-12 (ìµœì‹ )
- âœ… Ollama ì—°ê²° ì•ˆì •ì„± ê°œì„ 
- âœ… 500 Internal Server Error ë¬¸ì œ í•´ê²°
- âœ… ì„œë¹„ìŠ¤ ìƒíƒœ ëª¨ë‹ˆí„°ë§ ê°•í™”
- âœ… README.md ê°œì„  ë° ì„¤ì¹˜ ê°€ì´ë“œ ì¶”ê°€

### 2025-06-07
- âœ… Kakao Kanana 1.5-8B ëª¨ë¸ ì¶”ê°€ (BF16+Q8_0, 9.5GB)
- âœ… ê¸°ë³¸ ì—”ì§„ì„ sapieë¡œ ë³€ê²½
- âœ… GPU BF16 ì§€ì› í™•ì¸ ë° ìµœì í™”
- âœ… ì—”ì§„ ìš°ì„ ìˆœìœ„ ì¬ì¡°ì • (í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ìš°ì„ )
- âœ… ëŒ€ì²´ ì—”ì§„ ì‹œìŠ¤í…œ ê°œì„ 

### 2025-06-06
- âœ… Ollama GPU ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ
- âœ… ë³µìˆ˜ í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ì¶”ê°€
- âœ… ì‹¤ì‹œê°„ ë²ˆì—­ ì§„í–‰ë¥  í‘œì‹œ
- âœ… ì²­í¬ ë‹¨ìœ„ ì•ˆì •ì  ë²ˆì—­ ì‹œìŠ¤í…œ

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ë¡œ ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ `LICENSE` íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ“ ì—°ë½ì²˜

- **í”„ë¡œì íŠ¸ URL**: https://github.com/purestory/translation-service
- **ë¼ì´ë¸Œ ë°ëª¨**: http://itsmyzone.iptime.org/translation/

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-06-12  
**ë²„ì „**: 2.1.0  
**ì„œë²„**: itsmyzone.iptime.org  
**GPU**: RTX 3090 24GB (CUDA 12.8) 