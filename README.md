# ë²ˆì—­ ì„œë¹„ìŠ¤ (Translation Service)

AI ê¸°ë°˜ ë‹¤ì¤‘ ì—”ì§„ ë²ˆì—­ ì›¹ ì„œë¹„ìŠ¤ - GPU ê°€ì† ë¡œì»¬ AI ëª¨ë¸ íŠ¹í™”

## ğŸŒ ì„œë¹„ìŠ¤ ì ‘ì†

- **ì›¹ ì‚¬ì´íŠ¸**: http://itsmyzone.iptime.org/translation/
- **API**: http://itsmyzone.iptime.org/translation-api/

## ğŸ—ï¸ ì„œë¹„ìŠ¤ êµ¬ì¡°

```
ë²ˆì—­ ì„œë¹„ìŠ¤
â”œâ”€â”€ í”„ë¡ íŠ¸ì—”ë“œ: React + Vite â†’ nginx (í¬íŠ¸ 80/443)
â”œâ”€â”€ ë°±ì—”ë“œ: Node.js Express â†’ systemd (í¬íŠ¸ 3501)
â””â”€â”€ AI ëª¨ë¸: Ollama Docker Container â†’ GPU ê°€ì† (í¬íŠ¸ 11434)
```

## ğŸ¤– ì§€ì› ë²ˆì—­ ì—”ì§„

### GPU ê°€ì† Ollama ëª¨ë¸ (ìš°ì„ ìˆœìœ„)
1. **ollama-gemma2-sapie** (ê¸°ë³¸ê°’) - í•œêµ­ì–´ íŠ¹í™” Sapie ëª¨ë¸
2. **ollama-kanana-1.5** - Kakao Corp. Kanana 1.5-8B (BF16+Q8_0, 9.5GB)
3. **ollama-exaone3.5** - LG AI Research Exaone 3.5 (í•œêµ­ì–´ íŠ¹í™”)
4. **ollama-gemma2** - Google Gemma2 9B
5. **ollama-hyperclovax** - Naver HyperCLOVAX 3B (í•œêµ­ì–´ íŠ¹í™”)
6. **ollama-hyperclovax-1.5b** - Naver HyperCLOVAX 1.5B (ê²½ëŸ‰í™”)

### í´ë¼ìš°ë“œ API ëª¨ë¸ (ëŒ€ì²´ ì—”ì§„)
- **Google Gemini** - ê³ í’ˆì§ˆ ë‹¤êµ­ì–´ ë²ˆì—­
- **Groq Llama** - ê³ ì† ì¶”ë¡ 
- **OpenAI GPT** - ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­
- **Anthropic Claude** - ë¬¸ë§¥ ì´í•´ ìš°ìˆ˜
- **DeepL** - ì „ë¬¸ ë²ˆì—­ ì„œë¹„ìŠ¤

## ğŸ”§ í•˜ë“œì›¨ì–´ ì‚¬ì–‘

### GPU ì •ë³´
- **ëª¨ë¸**: NVIDIA RTX 3090
- **VRAM**: 24GB
- **CUDA**: 12.8
- **ì»´í“¨íŠ¸ ëŠ¥ë ¥**: 8.6 (BF16 ì§€ì›)

### AI ëª¨ë¸ í˜„í™©
```bash
# ì„¤ì¹˜ëœ ëª¨ë¸ í™•ì¸
curl -s http://localhost:11434/api/tags | jq '.models[].name'

# GPU ì‚¬ìš©ëŸ‰ í™•ì¸
nvidia-smi
```

## ğŸ”§ ì„œë¹„ìŠ¤ ê´€ë¦¬

### ìƒíƒœ í™•ì¸
```bash
# ë²ˆì—­ ì„œë¹„ìŠ¤ ìƒíƒœ
sudo systemctl status translation-service

# Ollama ì»¨í…Œì´ë„ˆ ìƒíƒœ
sudo docker ps | grep ollama

# GPU ì‚¬ìš©ëŸ‰
nvidia-smi

# ì„œë¹„ìŠ¤ ë¡œê·¸
sudo journalctl -u translation-service -f --no-pager
```

### ì„œë¹„ìŠ¤ ì œì–´
```bash
# ë²ˆì—­ ì„œë¹„ìŠ¤ ì¬ì‹œì‘
sudo systemctl restart translation-service

# Ollama ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
sudo docker restart ollama

# ì „ì²´ ì‹œìŠ¤í…œ ì¬ì‹œì‘
sudo systemctl restart translation-service
sudo docker restart ollama
sudo nginx -s reload
```

## ğŸ› ï¸ ê°œë°œ ë° ë°°í¬

### 1. í”„ë¡ íŠ¸ì—”ë“œ ìˆ˜ì •ì‹œ
```bash
cd /home/purestory/translation-service/vite-frontend
# ì½”ë“œ ìˆ˜ì • í›„
npm run build
cd .. && sudo nginx -s reload
```

### 2. ë°±ì—”ë“œ ìˆ˜ì •ì‹œ
```bash
cd /home/purestory/translation-service/backend
# ì½”ë“œ ìˆ˜ì • í›„
sudo systemctl restart translation-service
```

### 3. AI ëª¨ë¸ ì¶”ê°€ì‹œ
```bash
# ìƒˆ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
sudo docker exec ollama ollama pull <model_name>

# ì»¤ìŠ¤í…€ ëª¨ë¸ ë“±ë¡
sudo docker exec ollama ollama create <custom_name> -f /path/to/Modelfile

# ë°±ì—”ë“œì—ì„œ ì—”ì§„ ì¶”ê°€ í›„ ì¬ì‹œì‘ í•„ìš”
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
/home/purestory/translation-service/
â”œâ”€â”€ backend/               # Node.js ë°±ì—”ë“œ
â”‚   â”œâ”€â”€ server.js         # ë©”ì¸ ì„œë²„
â”‚   â”œâ”€â”€ routes/           # API ë¼ìš°íŠ¸
â”‚   â”‚   â””â”€â”€ translation.js # ë²ˆì—­ API
â”‚   â”œâ”€â”€ services/         # ë²ˆì—­ ì„œë¹„ìŠ¤
â”‚   â”‚   â””â”€â”€ translationService.js # ë©”ì¸ ë²ˆì—­ ë¡œì§
â”‚   â””â”€â”€ uploads/          # ì—…ë¡œë“œ íŒŒì¼
â”œâ”€â”€ vite-frontend/        # React í”„ë¡ íŠ¸ì—”ë“œ
â”‚   â”œâ”€â”€ src/              # ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”‚   â””â”€â”€ App.tsx       # ë©”ì¸ ì»´í¬ë„ŒíŠ¸
â”‚   â””â”€â”€ dist/             # ë¹Œë“œ ê²°ê³¼ (nginx ì„œë¹™)
â”œâ”€â”€ /home/purestory/ollama/models/ # AI ëª¨ë¸ ì €ì¥ì†Œ
â””â”€â”€ README.md
```

## ğŸš¨ ë¬¸ì œ í•´ê²°

### ë²ˆì—­ì´ ì•ˆë  ë•Œ
1. ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸: `sudo systemctl status translation-service`
2. Ollama ìƒíƒœ í™•ì¸: `sudo docker ps | grep ollama`
3. GPU ë©”ëª¨ë¦¬ í™•ì¸: `nvidia-smi`
4. ë¡œê·¸ í™•ì¸: `sudo journalctl -u translation-service -n 20`
5. ì„œë¹„ìŠ¤ ì¬ì‹œì‘: `sudo systemctl restart translation-service`

### GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ
```bash
# GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
nvidia-smi

# Ollama ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘ (ëª¨ë¸ ì–¸ë¡œë“œ)
sudo docker restart ollama

# ë¬´ê±°ìš´ ëª¨ë¸ ì œê±°
sudo docker exec ollama ollama rm <heavy_model>
```

### ì›¹ì‚¬ì´íŠ¸ê°€ ì•ˆ ì—´ë¦´ ë•Œ
1. nginx ìƒíƒœ í™•ì¸: `sudo systemctl status nginx`
2. ë¹Œë“œ íŒŒì¼ í™•ì¸: `ls -la /home/purestory/translation-service/vite-frontend/dist/`
3. í¬íŠ¸ í™•ì¸: `lsof -i :80,443,3501`
4. nginx ì¬ë¡œë“œ: `sudo nginx -s reload`

### ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì„ ë•Œ
```bash
# ëª¨ë¸ ëª©ë¡ í™•ì¸
curl -s http://localhost:11434/api/tags

# íŠ¹ì • ëª¨ë¸ ì •ë³´ í™•ì¸
curl -s http://localhost:11434/api/show -d '{"name": "model_name"}'

# ëª¨ë¸ ê°•ì œ ë¡œë“œ
curl -s http://localhost:11434/api/generate -d '{"model": "model_name", "prompt": "test"}'
```

## ğŸ“Š í˜„ì¬ ìš´ì˜ ìƒí™©

### ğŸ¯ í™œì„± ì„¤ì •
- **ê¸°ë³¸ ì—”ì§„**: `ollama-gemma2-sapie` (í•œêµ­ì–´ íŠ¹í™”)
- **ê¸°ë³¸ ì²­í¬ í¬ê¸°**: 10
- **ê¸°ë³¸ ë²ˆì—­ ëª¨ë“œ**: srt_direct
- **ìµœëŒ€ íŒŒì¼ í¬ê¸°**: 10MB
- **ëŒ€ì²´ ì—”ì§„**: í™œì„±í™” (ìë™ í´ë°±)

### ğŸš€ ì„±ëŠ¥ ìµœì í™”
- **GPU ê°€ì†**: RTX 3090 (24GB VRAM)
- **BF16 ì •ë°€ë„**: ì§€ì›ë¨
- **ë™ì‹œ ë²ˆì—­**: ì²­í¬ ë‹¨ìœ„ ë³‘ë ¬ ì²˜ë¦¬
- **ì‹¤ì‹œê°„ ì§„í–‰ë¥ **: WebSocket ìŠ¤íƒ€ì¼ í´ë§

### ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„ (í•œêµ­ì–´)
1. **Kanana 1.5** - Kakao (ì½”ë”©/ìˆ˜í•™/í•¨ìˆ˜í˜¸ì¶œ íŠ¹í™”)
2. **Sapie** - í•œêµ­ì–´ íŠ¹í™” Gemma2 íŠœë‹
3. **Exaone 3.5** - LG AI Research (í•œêµ­ì–´)
4. **HyperCLOVAX** - Naver (í•œêµ­ì–´)

## âš ï¸ ì¤‘ìš” ìš´ì˜ ê·œì¹™

### âœ… í•´ì•¼ í•  ê²ƒ
- ì½”ë“œ ìˆ˜ì • í›„ ë°˜ë“œì‹œ í…ŒìŠ¤íŠ¸
- ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš© (`/home/purestory/...`)
- systemdë¡œ ì„œë¹„ìŠ¤ ê´€ë¦¬
- Dockerë¡œ Ollama ê´€ë¦¬
- GPU ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§

### âŒ í•˜ì§€ ë§ ê²ƒ
- `~` ê²½ë¡œ ì‚¬ìš© (ì˜ë„ì¹˜ ì•Šì€ í´ë” ìƒì„±)
- pm2 ì‚¬ìš© (systemd ì‚¬ìš© ì¤‘)
- í¬íŠ¸ ë²ˆí˜¸ ì„ì˜ ë³€ê²½
- Ollama ëª¨ë¸ì„ ì§ì ‘ ì‚­ì œ
- GPU ì˜¤ë²„í´ëŸ­ (ì•ˆì •ì„± ìš°ì„ )

## ğŸ”‘ ì§€ì› ê¸°ëŠ¥

### ë²ˆì—­ ê¸°ëŠ¥
- **ë‹¤ì¤‘ ì—”ì§„**: 6ê°œ ë¡œì»¬ AI + 5ê°œ í´ë¼ìš°ë“œ API
- **ìë™ ëŒ€ì²´**: ì—”ì§„ ì‹¤íŒ¨ì‹œ ìë™ í´ë°±
- **ì‹¤ì‹œê°„ ì§„í–‰ë¥ **: ì²­í¬ë³„ ì§„í–‰ìƒí™© í‘œì‹œ
- **ë°°ì¹˜ ë²ˆì—­**: ëŒ€ìš©ëŸ‰ íŒŒì¼ ì•ˆì • ì²˜ë¦¬

### ìë§‰ ì§€ì›
- **íŒŒì¼ í˜•ì‹**: SRT, VTT, ASS
- **ë²ˆì—­ ëª¨ë“œ**: ìë™, SRT ì§ì ‘, êµ¬ë¶„ì
- **íƒ€ì„ìŠ¤íƒ¬í”„**: ì›ë³¸ ìœ ì§€
- **ì¸ì½”ë”©**: UTF-8 ìë™ ë³€í™˜

### API ê¸°ëŠ¥
- **í…ìŠ¤íŠ¸ ë²ˆì—­**: `/translation-api/translation/text`
- **íŒŒì¼ ë²ˆì—­**: `/translation-api/subtitle/translate`
- **ì—”ì§„ ëª©ë¡**: `/translation-api/translation/engines`
- **ì–¸ì–´ ëª©ë¡**: `/translation-api/translation/languages`
- **ë°°ì¹˜ ë²ˆì—­**: `/translation-api/translation/batch`

## ğŸ”„ ì—…ë°ì´íŠ¸ íˆìŠ¤í† ë¦¬

### 2025-06-07 (ìµœì‹ )
- âœ… Kakao Kanana 1.5-8B ëª¨ë¸ ì¶”ê°€ (BF16+Q8_0, 9.5GB)
- âœ… ê¸°ë³¸ ì—”ì§„ì„ sapieë¡œ ë³€ê²½
- âœ… GPU BF16 ì§€ì› í™•ì¸ ë° ìµœì í™”
- âœ… ì—”ì§„ ìš°ì„ ìˆœìœ„ ì¬ì¡°ì • (í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ìš°ì„ )
- âœ… ëŒ€ì²´ ì—”ì§„ ì‹œìŠ¤í…œ ê°œì„ 

### 2025-06-06
- âœ… Ollama GPU ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ
- âœ… ë³µìˆ˜ í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ì¶”ê°€
- âœ… ì‹¤ì‹œê°„ ë²ˆì—­ ì§„í–‰ë¥  í‘œì‹œ
- âœ… ì²­í¬ ë‹¨ìœ„ ì•ˆì •ì  ë²ˆì—­ ì‹œìŠ¤í…œ

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-06-07  
**ë²„ì „**: 2.0.0  
**ì„œë²„**: itsmyzone.iptime.org  
**GPU**: RTX 3090 24GB (CUDA 12.8) 